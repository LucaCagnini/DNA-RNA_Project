---
title: "Analysis of DNA methylation data"
author: Marco Cuscunà, Marina Mariano, Michele Carbonieri, Marco Centenaro, Luca Cagnini, Massimo Lanari
date: "2025-06-27"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# STEPS

### 1. Load raw data with minfi and create an object called RGset storing the RGChannelSet object.

The minfi library is an R package containing most of the functions that we will need for analyzing data coming from Illumina Infinium HumanMethylation arrays: it features tools for preprocessing, quality control, normalization, and for identifying differentially methylated loci. Similarly, the BiocManager package is a library featuring the Bioconductor functions needed for other steps in the identification of diffentially methylated positions, specifically during the preproceesing of data for normalization and for the removal of batch effects (accounting for technical variability). The RGChannelSet object is a data structure that stores the raw signal intensities from the red and green channels of the Illumina Infinium arrays. Load the required libraries: the first step is making sure that the libraries mentioned are installed, and installing them if they aren't already.

```{r}
##Installing and importing libraries
if (!requireNamespace("BiocManager", quietly = TRUE))
 install.packages("BiocManager")
BiocManager::install("minfi")
library(minfi)
options(repos = c(CRAN = "https://cloud.r-project.org"))
install.packages("rstudioapi")  # library that recover the path where the R project is
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))#set the active path where the R project is, automatically
library(knitr)
library(IlluminaHumanMethylation450kmanifest)
##Load raw data with minfi and create an object called RGset storing the RGChannelSet object  
rm(list=ls())

# Set the directory in which the raw data are stored and load the samplesheet
#using the function read.metharray.sheet
baseDir <- (file.path(getwd(), "Input_Data"))
targets <- read.metharray.sheet(baseDir)

#Create an object of class RGChannelSet using the function read.metharray.ex
RGset <- read.metharray.exp(targets = targets)
save(RGset,file="RGset.RData")
```

### 2. Create the dataframes Red and Green to store the red and green fluorescences respectively.

We now create two distinct objects to store the green and the red fluorescence data; the function data.frame extracts the data and converts it into dataframes.

```{r}
Red <- data.frame(getRed(RGset))
#Show the dimension, the internal structure and the first six row of Red object
dim(Red) 

#Repeat the process for the Green dataset
Green <- data.frame(getGreen(RGset))
dim(Green) 
```

### 3. Fill the following table: what are the Red and Green fluorescences for the address assigned to your group? Optional: check in the manifest file if the address corresponds to a Type I or a Type II probe and, in case of Type I probe, report its color.

We want to retrieve information relative to an assigned address from the dataframes.First, we generate simple tables with data referring exclusively to the given address, from both the green and the red dataframes. The variables with this information are then used to see if the given address refers to type 1 or type 2 probes, by using the column "Infinium_Design_Type" in the “Illumina450Manifest_clean” (which has to be loaded first). In our case, the probe is type II, so it can be either Red or Green. That is why AddressB is empty, and AddressA reports Type II. We extract all data related to sample, red fluorescence, green fluorescence and type and color to fill the data table.

```{r}
#Retrieve Red and Green fluorescence for the group address
address<-"13673406"
probe_red<-Red[rownames(Red)==address,]
probe_green<-Green[rownames(Green)==address,]

# Load the cleaned manifest file to check the type of the probe
load("Illumina450Manifest_clean.RData")
paste("Type of address A: ",Illumina450Manifest_clean[Illumina450Manifest_clean$AddressA_ID==address,'Infinium_Design_Type'])
paste("Type of address B: ",Illumina450Manifest_clean[Illumina450Manifest_clean$AddressB_ID==address,'Infinium_Design_Type'])
# Load SampleSheet for later
SampleSheet <- read.csv("Input_Data\\SampleSheet_Report_II.csv",header=T)

#extract all data related to sample, fluorescence, type and color to fill the table
df_address <- data.frame(Sample = colnames(probe_green),'Number of probes' = unlist(probe_red, use.names = FALSE) + unlist(probe_green, use.names = FALSE),'Type' = Illumina450Manifest_clean[Illumina450Manifest_clean$AddressA_ID == address, 'Infinium_Design_Type'])
knitr::kable(df_address, col.names=c("Sample","Number or probes", "Infinium design type"))
```

### 4. Create the object MSet.raw

We transform the raw intensity data in the RGset into methylated and unmethylated signals (MethylSet object). The minfi function preprocessRaw is the most basic way to do so; it matches up the different probes and color channels to build up the methylated and unmethylated signals, without normalizing the data. However, the function does adjust the fluorescence intensities accounting for the background noise. By using the command MSet.raw, we can observe that this object, along with the matrices of signal intesities, contains the phenotype data (such as sample IDs and phenotypic traits), feature data (such as probe IDs and genomic coordinates), and experiment data (which is the Metadata).

```{r}
# Use the preprocessRaw function to create the MSet.raw object from the RGChannelSet.
MSet.raw <- preprocessRaw(RGset)
save(MSet.raw,file="MSet_raw.RData")
dim(MSet.raw)
```

### 5. Perform the following quality checks and provide a brief comment to each step: • QCplot • check the intensity of negative controls using minfi • calculate detection pValues; for each sample, how many probes have a detection p-value higher than the threshold assigned to each group?

#### a. Generating the QC Plots.

The minfi getQC() function uses the log median of signal intensity distributions from both methylated and unmethylated channels. By plotting the two medians together, we obtain an initial assessment of data quality: the line separating “bad” from “good” samples is useful for visualizing the reliability of data: the signals plotted towards the right and upper parts of the QC plot are reliable. On the contrary, data with lower median values are qualitatively worse: we have 3 good-quality samples (above the line), 3 samples below the line but very close, and 2 bad ones; these samples require further investigation or have to be excluded from downstream analyses. Generally, good samples cluster together, while failed ones tend to separate. This approach helps initial quality assessment but should be supplemented with additional checks for background noise and sample preparation issues for a more comprehensive evaluation of data quality. The plot does not consider background signal levels, which can affect overall data quality. It also does not account for potential failures during sample preparation, which could impact signal integrity.

#### b. Negative control intensity check

This is useful for quality-checking different sample preparation steps of the experiment that may have gone wrong, like bisulfite conversion and hybridization. This is done by using the values of several internal control probes contained in the 450k array, which are stored in the RGset. These negative control probes are used for estimating background intensity in the array experiments with the controlStripPlot() function, which plots them to visually inspect their distribution across samples. These probes should have intensity values below 1000 unit and should always be between 100 and 1000 units, indicating minimal background signal. Values above this threshold may indicate high experimental issues affecting data quality.

#### c. Count Probes Exceeding Threshold

We now look into the detection of p-values for every sample to evaluate the reliability of the measurements for each probe. The minfi detectionP function (once again applied to the RGset) compares the total (meth + unmeth) signal for each probe to the background signal (estimated from the negative control probes explained above). Small p-values indicates reliable signal from a probe (significantly different from the background noise. Conversely, high p-values (typically \> 1%) are indicative of probe signal that is not distinguishable from background noise (hence, its reliability is low). Samples exhibiting high p-values are more likely to be qualitatively bad and should be removed or flagged. This check further improves the robustness and accuracy of the results, reducing the likelihood of making type 1 error (false positives).

```{r}
#a. Generating QC plot
qc <- getQC(MSet.raw)
qc
plotQC(qc)
#b. Negative control intensity check
#only two samples are above the threshold line. However, the majority of the samples are distributed close to the line, and more importantly are all grouped together.
controlStripPlot(RGset, controls="NEGATIVE")

#c. Count Probes Exceeding Threshold 
threshold<-0.05
detP <- detectionP(RGset)
exceed <- detP>0.05
num_exceed = colSums(exceed)
df_exceed <- data.frame(Sample=colnames(probe_green), Exceed_Positions=num_exceed,perc_exceed_probes=(means_of_columns <- colMeans(exceed))*100, row.names = NULL)
knitr::kable(df_exceed, col.names=c("Sample","Number of exceed probes", "Percentage of exceed probes"))
```

### 6. Calculate raw beta and M values and plot the densities of mean methylation values, dividing the samples in CTRL and DIS (suggestion: subset the beta and M values matrices in order to retain CTRL or DIS subjects and apply the function mean to the 2 subsets). Do you see any difference between the two groups?

The fluorescence intensity data is used to generate the methylation values. B and M values are metrics for quantifying methylation, derived directly from the fluorescence intensities measured by the methylation array: B-values quantify the proportion of DNA methylation at each CpG site, ranging from 0 (no methylation) to 1 (fully methylated). They are biologically intuitive and easy to interpret but tend to exhibit heteroscedasticity, particularly at the lower and upper extremes of the scale. M-values are calculated as the log2 ratio between methylated and unmethylated signal intensities. Unlike beta values, M-values are unbounded, spanning the entire real number line, and typically show homoscedasticity, which makes them statistically more robust for differential analysis. In this step, we computed the raw beta and M values using the functions getBeta() and getM(). We then calculated the mean methylation levels across all CpG sites separately for the two experimental groups — CTRL (wild type) and DIS (disease) — using the function apply() with MARGIN=1, which applies the calculation row-wise (i.e., across samples for each CpG site). The distributions of these mean values were estimated using the density() function, which performs kernel density estimation to approximate the continuous distribution of the data. For visualization, we used par(mfrow=c(1,2)) to split the plotting area into two side-by-side plots, allowing direct comparison between the beta and M value distributions. The first plot displays the density of mean beta values, with CTRL samples in blue (#0067E6) and DIS samples in red (#E50068). The second plot shows the same comparison for mean M values, following the same color scheme. The plotting functions plot() and lines() are used to create the density curves, while legend() places a key in the upper-right corner to indicate group identities. Biologically speaking, these density plots visualize the overall methylation states of the two groups. Methylation data typically exhibits a bimodal distribution, reflecting the fact that most CpG sites tend to be either highly methylated (beta close to 1) or largely unmethylated (beta close to 0), with fewer sites showing intermediate methylation levels. By comparing CTRL and disease groups, this plot helps to assess whether there are global shifts in methylation patterns, which could be indicative of disease-associated epigenetic alterations. Unfortunately, there doesn't seem to be a noticible difference in the methylation patters of CTRL and DIS samples. There only seems to be a slight variation between CTRL and DIS Beta Values distribution, as the DIS curve shows lower peaks.

```{r}
#6a Calculate raw beta and M values and plot the densities of mean methylation values, dividing the samples in CTRL and DIS

beta <- getBeta(MSet.raw)
M <- getM(MSet.raw)

ctrl_raw<- basename(targets[targets$Group == "CTRL", "Basename"])
dis_raw<- basename(targets[targets$Group == "DIS", "Basename"])
ctrlSet <- MSet.raw[, colnames(MSet.raw) %in% ctrl_raw]
disSet <- MSet.raw[, colnames(MSet.raw) %in% dis_raw]
ctrlBeta <- getBeta(ctrlSet)
ctrlM <- getM(ctrlSet)
disBeta <- getBeta(disSet)
disM <- getM(disSet)
mean_ctrlBeta <- apply(ctrlBeta, MARGIN=1, mean, na.rm=TRUE)
mean_disBeta <- apply(disBeta, MARGIN=1, mean, na.rm=TRUE)
mean_ctrlM <- apply(ctrlM, MARGIN=1, mean, na.rm=TRUE)
mean_disM <- apply(disM, MARGIN=1, mean, na.rm=TRUE)
d_mean_ctrlBeta <- density(mean_ctrlBeta, na.rm=TRUE)
d_mean_disBeta <- density(mean_disBeta, na.rm=TRUE)
d_mean_ctrlM <- density(mean_ctrlM, na.rm=TRUE)
d_mean_disM <- density(mean_disM, na.rm=TRUE)

#6b Plot the density obtained in point 6a
# Plot density of mean Beta and M values
par(mfrow=c(1,2))  # Set up the plotting area to have 1 row and 2 columns
# Plot density of mean Beta values
plot(d_mean_ctrlBeta, main="Density of Beta Values", col="#0067E6", lwd=2.5, xlab="Beta Values", ylab="Density")
lines(d_mean_disBeta, col="#E50068", lwd=2.5)
legend('topright', legend=c("CTRL", "DIS"), fill=c("#0067E6", "#E50068"), cex=0.5)
# Plot density of mean M values
plot(d_mean_ctrlM, main="Density of M Values", col="#0067E6", lwd=2.5, xlab="M Values", ylab="Density")
lines(d_mean_disM, col="#E50068", lwd=2.5)
legend('topright', legend=c("CTRL", "DIS"), fill=c("#0067E6", "#E50068"), cex=0.5)
# Reset plotting layout for subsequent plots
par(mfrow=c(1,1))
```

### 7. Normalize the data using the function assigned to each group and compare raw data and normalized data. Produce a plot with 6 panels in which, for both raw and normalized data, you show the density plots of beta mean values according to the chemistry of the probes, the density plot of beta standard deviation values according to the chemistry of the probes and the boxplot of beta values. Provide a short comment about the changes you observe. Optional: do you think that the normalization approach that you used is appropriate considering this specific dataset? Try to color the boxplots according to the group (WT and MUT) and check whether the distribution of methylation values is different between the two groups, before and after normalization

Our experimental goal is to identify biological variation, but technical variation can hide the real data. The aim of normalization methods is to remove unavoidable technical variation, in particular systematic bias. In order to increase the chance of identifying biological variation, normalisation is the starting point and the go to way. The easiest way to review the distribution is with box plot visualisation. Usually the values that we are interested in are the outliers, lower quartile values and median. Discussion of results using preprocessNoob; Let's now consider the differences for each plot: Considering the Raw Beta Mean vs preprocessNoob Beta Mean we can see that the density curves show that type I and type II probes have different distributions in raw data while after applying the function preprocessNoob() differences are reduced. Considering Raw Beta SD vs preprocessNoob beta SD, we can see SD is diminished after normalisation, even if by a small amount. Considering the Boxpot normalisation, distributions after normalisation appear more similar, showing a good correction of batch effects. it is necessary to underlie that preprocessNoob is a function created for background correction, removing noise, and dye bias correction. Function like preprocessQuantile impose specific corrections for quantile distributions, that preprocessNoob doesn't provide. Noob procedure is often suggested and has a greater effect considering M-values scales (Timothy et al., 2013)

```{r}
# Subset the manifest into Type I (dfI) and Type II (dfII) probes based on Infinium_Design_Type
dfI <- Illumina450Manifest_clean[Illumina450Manifest_clean$Infinium_Design_Type == "I", ]
dfI <- droplevels(dfI)
dfII <- Illumina450Manifest_clean[Illumina450Manifest_clean$Infinium_Design_Type == "II", ]
dfII <- droplevels(dfII)

# Normalize using preprocessNoob
preprocessNoob_results <- preprocessNoob(RGset,dyeMethod="single")

# Separation of type I and type II probes.
beta_I <- beta[rownames(beta) %in% dfI$IlmnID, ]
beta_II <- beta[rownames(beta) %in% dfII$IlmnID, ]

# Calculate raw mean and sd
mean_of_beta_I <- apply(beta_I, 1, mean, na.rm = TRUE)
mean_of_beta_II <- apply(beta_II, 1, mean, na.rm = TRUE)
d_mean_of_beta_I <- density(mean_of_beta_I, na.rm = TRUE)
d_mean_of_beta_II <- density(mean_of_beta_II, na.rm = TRUE)
sd_of_beta_I <- apply(beta_I, 1, sd, na.rm = TRUE)
sd_of_beta_II <- apply(beta_II, 1, sd, na.rm = TRUE)
d_sd_of_beta_I <- density(sd_of_beta_I, na.rm = TRUE)
d_sd_of_beta_II <- density(sd_of_beta_II, na.rm = TRUE)

# Extract normalized beta values
beta_preprocessNoob <- getBeta(preprocessNoob_results)
beta_preprocessNoob_I <- beta_preprocessNoob[rownames(beta_preprocessNoob) %in% dfI$IlmnID, ]
beta_preprocessNoob_II <- beta_preprocessNoob[rownames(beta_preprocessNoob) %in% dfII$IlmnID, ]

# Calculate normalized mean and sd
mean_of_beta_preprocessNoob_I <- apply(beta_preprocessNoob_I, 1, mean, na.rm = TRUE)
mean_of_beta_preprocessNoob_II <- apply(beta_preprocessNoob_II, 1, mean, na.rm = TRUE)
d_mean_of_beta_preprocessNoob_I <- density(mean_of_beta_preprocessNoob_I, na.rm = TRUE)
d_mean_of_beta_preprocessNoob_II <- density(mean_of_beta_preprocessNoob_II, na.rm = TRUE)
sd_of_beta_preprocessNoob_I <- apply(beta_preprocessNoob_I, 1, sd, na.rm = TRUE)
sd_of_beta_preprocessNoob_II <- apply(beta_preprocessNoob_II, 1, sd, na.rm = TRUE)
d_sd_of_beta_preprocessNoob_I <- density(sd_of_beta_preprocessNoob_I, na.rm = TRUE)
d_sd_of_beta_preprocessNoob_II <- density(sd_of_beta_preprocessNoob_II, na.rm = TRUE)

# Set up the layout for the plots: 2 rows, 3 columns
par(mfrow = c(2, 3))

# Top Row: Raw Data
# Plot densities of mean beta values (raw)
plot(d_mean_of_beta_I, col = "blue", main = "Raw Beta Mean", xlim = c(0, 1), ylim = c(0, 5))
lines(d_mean_of_beta_II, col = "red")
legend("top", legend = c("Type I", "Type II"), col = c("blue", "red"), lty = 1, cex = 0.8)

# Plot densities of standard deviation beta values (raw)
plot(d_sd_of_beta_I, col = "blue", main = "Raw Beta SD", xlim = c(0, 0.6), ylim = c(0, 60))
lines(d_sd_of_beta_II, col = "red")
legend("topright", legend = c("Type I", "Type II"), col = c("blue", "red"), lty = 1, cex = 0.8)

# Boxplot of raw beta values
targets$Group <- as.factor(targets$Group)
palette(c("#E50068", "#0067E6"))
boxplot(beta, col = targets$Group)
title('Boxplot of raw Beta values')

# Bottom Row: Normalized Data
# Plot densities of mean beta values (preprocessNoob)
plot(d_mean_of_beta_preprocessNoob_I, col = "blue", main = "preprocessNoob Beta Mean", xlim = c(0, 1), ylim = c(0, 5))
lines(d_mean_of_beta_preprocessNoob_II, col = "red")
legend("top", legend = c("Type I", "Type II"), col = c("blue", "red"), lty = 1, cex = 0.8)

# Plot densities of standard deviation beta values (preprocessNoob)
plot(d_sd_of_beta_preprocessNoob_I, col = "blue", main = "preprocessNoob Beta SD", xlim = c(0, 0.6), ylim = c(0, 60))
lines(d_sd_of_beta_preprocessNoob_II, col = "red")
legend("topright", legend = c("Type I", "Type II"), col = c("blue", "red"), lty = 1, cex = 0.8)

# Boxplot of normalized beta values
boxplot(beta_preprocessNoob, col = targets$Group)
title('Boxplot of normalized Beta values')

# Reset par settings to default (1 row, 1 column) to avoid affecting subsequent plots
par(mfrow = c(1, 1))
```

### 8. Perform a PCA on the matrix of normalized beta values generated in step 7. Comment the plot (Do you see any outlier? Do the samples divide according to the group? Do they divide according to the sex of the samples? Do they divide according to the batch, that is the column Sentrix_ID?).

PCA is a dimensionality reduction technique that combines dimensions present in the original dataset to obtain new dimensions (principal components) in a new coordinates system. Principal components are ranked by how much variability of the original data they explain. Principal components can be used to extract and visualize patterns in the original data, and also to spot artifacts such as batch effects affecting variability. In our specific case, if we consider the sex variable, there is a clear separation on PC1. The group variable does not seem to produce any separation. Considering the Batch, it appears to be a slight batch effect, although all the samples are clustered together, except for one sample, that also has its own batch. Considering that is only one sample, we cannot conclude that it separates from the rest of the samples due a batch effect. The group variable (DIS or CTRL) does not seem to correlate with any separation.

```{r}
pca_results <- prcomp(t(beta_preprocessNoob), scale = TRUE)
install.packages("factoextra")
library(factoextra)
fviz_eig(pca_results, addlabels = TRUE, xlab = 'PC number', ylab ='% of variance', barfill = "#0063A6", barcolor = "black")

# PCA plot per Group
targets$Group <- as.factor(targets$Group)
palette(c("#E50068", "#0067E6"))
plot(pca_results$x[, 1], pca_results$x[, 2], cex = 1, pch = 19, col = targets$Group, xlab = "PC1", ylab = "PC2", xlim = c(-700, 700), ylim = c(-700, 700), main = 'PCA (Groups)')
text(pca_results$x[, 1], pca_results$x[, 2], labels = rownames(pca_results$x), cex = 0.4, pos = 3)
legend("bottomright", legend = levels(targets$Group), col = c(1, 2), pch = 19, cex = 1.0)

# PCA plot per Sex
targets$Sex <- as.factor(targets$Sex)
palette(c("#C364CA", "#8BC4F9"))
plot(pca_results$x[, 1], pca_results$x[, 2], cex = 1, pch = 19, col = targets$Sex, xlab = "PC1", ylab = "PC2", xlim = c(-700, 700), ylim = c(-700, 700), main = 'PCA (Sex)')
text(pca_results$x[, 1], pca_results$x[, 2], labels = rownames(pca_results$x), cex = 0.4, pos = 3)
legend("bottomright", legend = levels(targets$Sex), col = c(1:nlevels(targets$Sex)), pch = 19, cex = 1.0)

# PCA plot colored by batch
targets$Slide <- as.factor(targets$Slide)
palette(rainbow(length(levels(targets$Slide)))) 
plot(pca_results$x[, 1], pca_results$x[, 2], 
     cex = 1, pch = 19, col = as.numeric(targets$Slide),
     xlab = "PC1", ylab = "PC2", 
     xlim = c(-700, 700), ylim = c(-700, 700),
     main = "PCA (Batch)")
text(pca_results$x[, 1], pca_results$x[, 2], 
     labels = rownames(pca_results$x), cex = 0.4, pos = 3)
legend("bottomright", 
       legend = levels(targets$Slide), 
       col = 1:length(levels(targets$Slide)), 
       pch = 19, cex = 1.0)
```

### 9. Using the matrix of normalized beta values generated in step 7, identify differentially methylated probes between CTRL and DIS groups using the function assigned to each group.

To assess the significance of a difference in methylation between the two probes is essential to perform a statistical validation procedure. Statistical tests that work on two groups can be divided into parametrical and non-parametrical tests. The Mann-Whitney U-test is a non-parametrical test and therefore is less powerful that parametrical ones. Also, considering the limited number of samples analysed (4 DIS and 4 CTRL) there is only a limited number of p-values that the test can assign to each probe, resulting in a lot of replicate p-values in the output of the test.

```{r}
pheno = SampleSheet
MannWhitney_function <- function(x) {
  u_test <- wilcox.test(x ~ pheno$Group, exact=FALSE, correct = FALSE)
  return(u_test$p.value)
}

#execute the function
pValues_u_test <- apply(beta_preprocessNoob,1, MannWhitney_function)
final_u_test <- data.frame(beta_preprocessNoob, pValues_u_test)

# Count the number of probes with a p-value <= 0.05
final_utest_th <- final_u_test[final_u_test$pValues_u_test <= 0.05, ]
hist(final_u_test$pValues_u_test, main = "P-value distribution (u-test)", xlab ='p-val')
abline(v = 0.05, col = "red")
paste("Number of probes with a p-value ≤ 0.05: ",  dim(final_utest_th)[1])
```

### 10. Apply multiple test correction and set a significant threshold of 0.05. How many probes do you identify as differentially methylated considering nominal pValues? How many after Bonferroni correction? How many after BH correction?

Multiple test correction is necessary to lower possible errors such as the Family Wise Error Rate (FWER) and the False Discovery Rate (FDR) when testing for multiple variables. In our case we tested for 450k cpg sites, so multiple testing correction is vital. With this many tests, the Bonferroni correction will likely yield no significant results, since it is a very strict correction method. One less strict method is the Benjamini-Hotchberg correction, that is usually preferable when performing multiple testing correction. In our case, considering nominal p-values we end up with 11052 significant probes With Bonferroni correction we end up with 0 significant probes. With Benjamini-Hotchberg correction we end up with 0 significant probes.

```{r}
corrected_pValues_BH <- p.adjust(final_u_test$pValues_u_test,"BH")
corrected_pValues_Bonf <- p.adjust(final_u_test$pValues_u_test,"bonferroni")

final_u_test_corrected <- data.frame(final_u_test, corrected_pValues_BH, corrected_pValues_Bonf)

#How many probes survive the multiple test correction?
dim(final_u_test[final_u_test$pValues_u_test<=0.05,])
dim(final_u_test[final_u_test$corrected_pValues_BH<=0.05,])
dim(final_u_test_corrected[final_u_test_corrected$corrected_pValues_BH<=0.05,])
dim(final_u_test_corrected[final_u_test_corrected$corrected_pValues_Bonf<=0.05,])

# plotting
par(mfrow=c(1,1))
boxplot(final_u_test_corrected [,9:11], col = c("#7038FF", "#C7FF38", "seashell2"),names=NA, main='p-val before/after corrections')
legend("topright", legend=c("raw", "BH", "Bonferroni"),col=c("#7038FF", "#C7FF38", "seashell2"),pch=19, cex=0.5, xpd=TRUE)
```

### 11. Produce a volcano plot and a Manhattan plot of the results of differential methylation analysis

#### a. Volcano Plot

Each point in the plot corresponds to a specific CpG probe, for which the average methylation difference between the two groups has been calculated and is shown on the x-axis. In particular, the delta beta value indicates the average difference in methylation between the groups, with positive values suggesting higher methylation in the control group and negative values indicating increased methylation in the diseased group. The y-axis represents the statistical significance of each comparison, expressed as -log10(p-value), where p-value is obtained through the Mann-Whitney U test. This non-parametric test is suitable for comparing distributions between two independent groups and does not require assumptions of normality. In the plot, red points highlight CpG sites that meet two simultaneous criteria: a p-value lower than 0.05 and an absolute methylation difference equal to or greater than 10%. This filtering step ensures that only probes which are not only statistically significant but also biologically relevant in terms of methylation change are emphasized. Grey points, on the other hand, represent probes that fail to meet at least one of these criteria and are therefore considered non-significant. The data distribution shows a characteristic "stepped" pattern along the y-axis. This effect is consistent with the use of a non-parametric test such as the Mann-Whitney U, which, especially in datasets with limited size or discrete values, may produce repeated p-values, resulting in a visually segmented depiction of significance levels. Lastly, it is observed that the CpG sites with the greatest methylation differences between groups also tend to be those with higher negative log-transformed p-values, suggesting a consistency between the extent of epigenetic variation and its statistical significance.

```{r}
volcano_u_test <- data.frame(beta_preprocessNoob, pValues_u_test)
beta_volcano <- volcano_u_test[,1:8]
beta_volcano_groupCTRL <- beta_volcano[,pheno$Group=="CTRL"]
mean_beta_volcano_groupCTRL <- apply(beta_volcano_groupCTRL,1,mean)
beta_volcano_groupDIS <- beta_volcano[,pheno$Group=="DIS"]
mean_beta_volcano_groupDIS <- apply(beta_volcano_groupDIS,1,mean)

#Now we can calculate the difference between average values:
delta_volcano <- mean_beta_volcano_groupCTRL-mean_beta_volcano_groupDIS

#Now we create a dataframe with two columns, one containing the delta values and the other with the -log10 of p-values
toVolcPlot_volcano <- data.frame(delta_volcano, -log10(volcano_u_test$pValues_u_test))

#This line is useful to format in a good way the graph to avoid overlap of the legend with our graph, hiding data.
par(mar = c(5, 4, 4, 9), xpd = TRUE)

#create Volcano Plot
plot(toVolcPlot_volcano[,1], toVolcPlot_volcano[,2],
     pch = 16, cex = 0.5, col = "grey70",
     xlab = "delta beta (ctrl - dis)", ylab = "-log10(p-value)",
     xlim = c(-0.7, 0.7),
     ylim = c(0, max(toVolcPlot_volcano[,2])),
     asp = 0.5)

#add significance line at p-value threshold 0.05 
abline(h = -log10(0.05), col = "red", lty = 2, xpd = FALSE)

#add 10% differences in methylation line
abline(v = 0.1, col = "red", lty = 2, xpd = FALSE)
abline(v = -0.1, col = "red", lty = 2, xpd = FALSE)

# Highlight significant results
bh_sig <- toVolcPlot_volcano[
  volcano_u_test$pValues_u_test < 0.05 &
    abs(toVolcPlot_volcano[,1]) > 0.1, ]

points(bh_sig[,1], bh_sig[,2], pch = 16, cex = 0.8, col = "red")

# Legend
legend("bottomright",inset = c(-0.4, 0.12),
       legend = c("non significant",  "p < 0.05 & methylation difference ≥ 10%"),
       col = c("grey70", "red"),
       pch = 16, pt.cex = c(0.5, 0.8), cex = 0.7)



```

#### b. Manhattan Plot

The Manhattan plot was generated based on the p-values obtained from the Mann-Whitney U statistical test. For each CpG probe, chromosomal information (chromosome number and genomic position) was retrieved and associated with the corresponding statistical significance value. The adopted significance threshold was set at p-value \< 0.05, consistent with the threshold used in the volcano plot, and is represented as an horizontal reference line in the graph. However, the resulting visualization does not display clearly defined peaks or continuous gradients of significance, but rather a distribution across discrete horizontal levels. This behavior reflects an intrinsic characteristic of the Mann-Whitney test which, in the presence of a limited number of samples per group (in this case, 8 per CpG site), returns a restricted set of distinct p-values. As a result, the points in the Manhattan plot tend to align along a few levels of significance, producing a “banded” visual effect rather than a continuous one. Despite having a limited impact in terms of visual immediacy, the plot accurately represents the genomic distribution of the tested probes and provides a concise overview of their statistical significance along the chromosomes. For major clarity, given that displaying all the significant probe names directly on the plot would be overly complex and visually unclear, the script was designed to export a .csv file ("significantly_probes.csv") listing all probes that exceed the adopted significance threshold (p-value \< 0.05). For each probe, the file includes its identifier, ordered by chromosome from 1 to 24 (where 23 = X and 24 = Y), and the p-value obtained through the Mann-Whitney U test. This output could serves as a useful resource for further analyses on significantly variable CpG sites per chromosome.

```{r}
install.packages("qqman")
library(qqman)

#We prepare the annotation of the p-value per probe, recovering CHR, MAPINFO, IlmnID
final_u_test_manhattan <- data.frame(rownames(volcano_u_test),volcano_u_test)
colnames(final_u_test_manhattan)[1] <- "IlmnID"

final_u_test_manhattan_annotated <- merge(final_u_test_manhattan, Illumina450Manifest_clean,by="IlmnID")


# Now we can create the input for the Manhattan plot analysis. The input object should contain 4 info: probe, chromosome, position on the chromosome and p-value. We will select these columns in the final_u_test_manhattan_annotated object
input_Manhattan <- final_u_test_manhattan_annotated[colnames(final_u_test_manhattan_annotated) %in% c("IlmnID","CHR","MAPINFO","pValues_u_test")]

# It is better to reorder the levels of the CHR
order_chr <- c("1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","X","Y")
input_Manhattan$CHR <- factor(input_Manhattan$CHR,levels=order_chr )



# the column "CHR" should be numeric --> we will convert factors to numbers
input_Manhattan$CHR <- as.numeric(input_Manhattan$CHR)

# and finally we can produce our Manhattan plot
par(xaxs = "i")  
manhattan(input_Manhattan, snp="IlmnID",chr="CHR", bp="MAPINFO", p="pValues_u_test",col=rainbow(24) )
abline(h = -log10(0.05), col = "red", lty = 2)


# Extract the ids, chromosome and Mann-Whitney U test p-values of each probes with p-value above the threshold
significantly_probes <- input_Manhattan[input_Manhattan$pValues_u_test < 0.05, ]
#reorder these ids per chromosomes and insert them into the file.csv useful for possible further analysis
probes_table <- significantly_probes[, c("IlmnID", "pValues_u_test","CHR")]
probes_table <- probes_table[order(probes_table$CHR), ]
write.csv(probes_table, "significantly_probes.csv", row.names = FALSE)
```

### 12. Produce an heatmap of the top 100 significant, differentially methylated probes.

We produced an heatmap of the 100 significant methylated probes. To perform this we used the function heatmap.2 of gplots package. After loaded the library we extracted the top 100 most significant CpG probes and performed the heatmap, using euclidean distance. We used average linkage distance method because it gives the best results in terms of similarity of profiles between clusters. We have also tried single and complete; the latter gives very similar results as average linkage, but this one is preferable as it is generally more robust. We observed no significant differences between control and disease conditions (CTRL and DIS), but only between M ad F (Sex).

```{r}
install.packages("gplots")
library(gplots)

# It wants as input a matrix. As an heatmap on several thousands of probes is computationally demanding, for our analysis we will use just the top 100 most significant CpG probes. We will extract only beta values for these top 100 probes and convert them in a matrix:
input_heatmap=as.matrix(volcano_u_test[1:100,1:8])


# Finally, we we create a bar of colors for Group A or Group B membership
colorbar_group <- c("green","orange","orange","green","orange","orange","green","green")


# We used average linkage mapping to find the distance relation between clusters
heatmap.2(input_heatmap,col=terrain.colors(100),Rowv=T,Colv=T,hclustfun = function(x) hclust(x,method = 'average'),dendrogram="both",key=T,ColSideColors=colorbar_group,density.info="none",trace="none",scale="none",symm=F,main="Average linkage - Groups")

#We performed also the analysis comparing sample using sex groups
colorbar_sex <- c("cyan","cyan","pink","cyan","pink","pink","pink","pink")


# Average
heatmap.2(input_heatmap,col=colorRampPalette(c("cyan","grey","pink"))(100),Rowv=T,Colv=T,hclustfun = function(x) hclust(x,method = 'average'),dendrogram="both",key=T,ColSideColors=colorbar_sex,density.info="none",trace="none",scale="none",symm=F,main="Average linkage - Sex")
```
